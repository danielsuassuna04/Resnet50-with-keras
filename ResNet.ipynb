{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlxpHWP9QO23"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS90cSVC32N7"
      },
      "outputs": [],
      "source": [
        "def data_augmentation():\n",
        "    data_augmentation = keras.models.Sequential()\n",
        "    data_augmentation.add(keras.layers.RandomFlip('horizontal'))\n",
        "    data_augmentation.add(keras.layers.RandomRotation(0.2))\n",
        "    data_augmentation.add(keras.layers.RandomZoom(0.2))\n",
        "    data_augmentation.add(keras.layers.RandomContrast(0.2))\n",
        "\n",
        "\n",
        "\n",
        "    return data_augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKB8lM7NQUwV"
      },
      "outputs": [],
      "source": [
        "def bloco_identidade(X, f, filters, initializer=keras.initializers.random_uniform):\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = keras.layers.Conv2D(filters=F1, kernel_size=1, strides=(1,1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
        "    X = keras.layers.BatchNormalization(axis=3)(X)\n",
        "    X = keras.layers.Activation('relu')(X)\n",
        "\n",
        "    X = keras.layers.Conv2D(filters=F2, kernel_size=(f, f), strides=(1,1), padding='same', kernel_initializer=initializer(seed=0))(X)\n",
        "    X = keras.layers.BatchNormalization(axis=3)(X)\n",
        "    X = keras.layers.Activation('relu')(X)\n",
        "\n",
        "    X = keras.layers.Conv2D(filters=F3, kernel_size=(1, 1), strides=(1,1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
        "    X = keras.layers.BatchNormalization(axis=3)(X)\n",
        "\n",
        "    X = keras.layers.Add()([X, X_shortcut])\n",
        "    X = keras.layers.Activation('relu')(X)\n",
        "\n",
        "    return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IcbvhZ3Q9CY"
      },
      "outputs": [],
      "source": [
        "def bloco_convolucional(X, f, filters, s=2, initializer=keras.initializers.glorot_uniform):\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = keras.layers.Conv2D(filters=F1, kernel_size=1, strides=(s, s), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
        "    X = keras.layers.BatchNormalization(axis=3)(X)\n",
        "    X = keras.layers.Activation('relu')(X)\n",
        "\n",
        "    X = keras.layers.Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=initializer(seed=0))(X)\n",
        "    X = keras.layers.BatchNormalization(axis=3)(X)\n",
        "    X = keras.layers.Activation('relu')(X)\n",
        "\n",
        "    X = keras.layers.Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=initializer(seed=0))(X)\n",
        "    X = keras.layers.BatchNormalization(axis=3)(X)\n",
        "\n",
        "    X_shortcut = keras.layers.Conv2D(F3, (1, 1), strides=(s, s), kernel_initializer=initializer(seed=0))(X_shortcut)\n",
        "    X_shortcut = keras.layers.BatchNormalization(axis=3)(X_shortcut)\n",
        "\n",
        "    X = keras.layers.Add()([X, X_shortcut])\n",
        "    X = keras.layers.Activation('relu')(X)\n",
        "\n",
        "    return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SPmKcuWRIuM"
      },
      "outputs": [],
      "source": [
        "def ResNet50(input_shape=(64, 64, 3), classes=6, training=False):\n",
        "    X_input = keras.layers.Input(input_shape)\n",
        "    X_input = data_augmentation()(X_input)\n",
        "    X = keras.layers.ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    X = keras.layers.Conv2D(64, (7, 7), strides=(2, 2), kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
        "    X = keras.layers.BatchNormalization(axis=3)(X)\n",
        "    X = keras.layers.Activation('relu')(X)\n",
        "    X = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = bloco_convolucional(X, f=3, filters=[64, 64, 256], s=1)\n",
        "    X = bloco_identidade(X, 3, [64, 64, 256])\n",
        "    X = bloco_identidade(X, 3, [64, 64, 256])\n",
        "\n",
        "    X = bloco_convolucional(X, f=3, filters=[128, 128, 512], s=2)\n",
        "    X = bloco_identidade(X, f=3, filters=[128, 128, 512])\n",
        "    X = bloco_identidade(X, f=3, filters=[128, 128, 512])\n",
        "    X = bloco_identidade(X, f=3, filters=[128, 128, 512])\n",
        "\n",
        "    X = bloco_convolucional(X, f=3, filters=[256, 256, 1024], s=2)\n",
        "    X = bloco_identidade(X, f=3, filters=[256, 256, 1024])\n",
        "    X = bloco_identidade(X, f=3, filters=[256, 256, 1024])\n",
        "    X = bloco_identidade(X, f=3, filters=[256, 256, 1024])\n",
        "    X = bloco_identidade(X, f=3, filters=[256, 256, 1024])\n",
        "    X = bloco_identidade(X, f=3, filters=[256, 256, 1024])\n",
        "\n",
        "    X = bloco_convolucional(X, f=3, filters=[512, 512, 2048], s=2)\n",
        "    X = bloco_identidade(X, f=3, filters=[512, 512, 2048])\n",
        "    X = bloco_identidade(X, f=3, filters=[512, 512, 2048])\n",
        "\n",
        "    X = keras.layers.AveragePooling2D((2, 2))(X)\n",
        "\n",
        "    X = keras.layers.Flatten()(X)\n",
        "    X = keras.layers.Dropout(0.5)(X)\n",
        "    X = keras.layers.Dense(classes, activation='softmax', kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
        "\n",
        "    model = keras.Model(inputs=X_input, outputs=X)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2z05H1aRkBp",
        "outputId": "842c1538-200a-4c2a-969c-229143afb0c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "batch_size = 64\n",
        "print(test_images.shape)\n",
        "train_images.shape = (60000,28,28,1)\n",
        "test_images.shape = (10000,28,28,1)\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (64, 64))\n",
        "    return image, label\n",
        "X_train = train_images.astype('float32') / 255.0\n",
        "X_test = test_images.astype('float32') / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "train_dataset = (train_dataset\n",
        "                 .map(lambda x, y: preprocess(x, y))\n",
        "                 .shuffle(buffer_size=10000)\n",
        "                 .batch(batch_size)\n",
        "                 .prefetch(1))\n",
        "test_dataset = (test_dataset\n",
        "                .map(lambda x, y: preprocess(x, y))\n",
        "                .batch(batch_size)\n",
        "                .prefetch(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL3dTz3QUJ__"
      },
      "outputs": [],
      "source": [
        "model = ResNet50(input_shape=(64, 64, 1), classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv1LHZKGUeIY"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01,weight_decay=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQYR2FoJUuz3"
      },
      "outputs": [],
      "source": [
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    filepath='best_model.weights.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    save_weights_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWIUJwPDUrJS",
        "outputId": "4ba9e7c3-c8f6-4084-9183-0a49a128bee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9826\n",
            "Epoch 1: val_loss did not improve from 0.03739\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0630 - accuracy: 0.9826 - val_loss: 0.0562 - val_accuracy: 0.9860\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9843\n",
            "Epoch 2: val_loss did not improve from 0.03739\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0596 - accuracy: 0.9843 - val_loss: 0.0982 - val_accuracy: 0.9719\n",
            "Epoch 3/10\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9791\n",
            "Epoch 3: val_loss did not improve from 0.03739\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0800 - accuracy: 0.9791 - val_loss: 10.3294 - val_accuracy: 0.8198\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9849\n",
            "Epoch 4: val_loss improved from 0.03739 to 0.03321, saving model to best_model.weights.h5\n",
            "938/938 [==============================] - 44s 46ms/step - loss: 0.0604 - accuracy: 0.9849 - val_loss: 0.0332 - val_accuracy: 0.9898\n",
            "Epoch 5/10\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9851\n",
            "Epoch 5: val_loss did not improve from 0.03321\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0601 - accuracy: 0.9851 - val_loss: 0.2054 - val_accuracy: 0.9646\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9843\n",
            "Epoch 6: val_loss did not improve from 0.03321\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0651 - accuracy: 0.9843 - val_loss: 0.0531 - val_accuracy: 0.9862\n",
            "Epoch 7/10\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9890\n",
            "Epoch 7: val_loss did not improve from 0.03321\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0403 - accuracy: 0.9890 - val_loss: 0.0634 - val_accuracy: 0.9821\n",
            "Epoch 8/10\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9884\n",
            "Epoch 8: val_loss did not improve from 0.03321\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0426 - accuracy: 0.9884 - val_loss: 0.0416 - val_accuracy: 0.9875\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9808\n",
            "Epoch 9: val_loss did not improve from 0.03321\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0850 - accuracy: 0.9808 - val_loss: 0.0386 - val_accuracy: 0.9883\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9897\n",
            "Epoch 10: val_loss did not improve from 0.03321\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0387 - accuracy: 0.9897 - val_loss: 0.0377 - val_accuracy: 0.9885\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f7912450210>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_dataset, epochs=10, validation_data=test_dataset,callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tn5qhc8dpUq"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"best_model.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NODrei5W_DP",
        "outputId": "1c16403b-967a-4ff9-c787-04616f5ae79a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 11ms/step - loss: 0.0332 - accuracy: 0.9898\n",
            "Accuracy: 98.98%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {round(model.evaluate(test_dataset)[1],5)*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzwwEHLfdpUq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}